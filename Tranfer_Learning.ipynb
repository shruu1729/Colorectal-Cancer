{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b032f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D, BatchNormalization, concatenate, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dataset = ImageDataGenerator(rescale=1./255)\n",
    "test_dataset = ImageDataGenerator(rescale=1./255)\n",
    "validation_dataset = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "#BATCH_SIZE = 32\n",
    "#IMG_SIZE = (160, 160)\n",
    "#train_dir='Database/Train/'\n",
    "#validation_dir='Database/Valid/'\n",
    "#train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            #shuffle=True,\n",
    "                                                            #batch_size=BATCH_SIZE,\n",
    "                                                            #image_size=IMG_SIZE)\n",
    "#validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                # shuffle=True,\n",
    "                                                                # batch_size=BATCH_SIZE,\n",
    "                                                                 #image_size=IMG_SIZE)\n",
    "#import tensorflow as tf\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#train_dataset= train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "#test_datagen = test_datagen.prefetch(buffer_size=AUTOTUNE)\n",
    " \n",
    "batchsize = 10\n",
    "train_generator=train_dataset.flow_from_directory('Database/Train/', \n",
    "                                                  target_size=(224, 224), \n",
    "                                                  batch_size=batchsize, \n",
    "                                                  class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_dataset.flow_from_directory('Database/Valid',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "test_generator = test_dataset.flow_from_directory('Database/Test/',\n",
    "       target_size=(224, 224),\n",
    "       batch_size=batchsize,\n",
    "       class_mode='categorical',\n",
    "       shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2b684",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "VGG Net: VGG network has simplest structure with 3 x 3 filter in each convolutional layer. There are two variant available VGG-16 and VGG1-9. In the image above VGG network is presneted.\n",
    "Transfer Learning: The VGGNet pre-trained on ImageNet and Inception module for transfer learning, and trained the newly formed neural networks using new datasets. The approach combines the advantages of the VGGNet and Inception module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG19\n",
    "base_model1=keras.applications.vgg19.VGG19(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "#MobileNet\n",
    "base_model2=tf.keras.applications.MobileNetV2(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "#ResNet50 \n",
    "base_model3 = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=1000,\n",
    "    classifier_activation='softmax')\n",
    "\n",
    "\n",
    "\n",
    "#VGG16\n",
    "base_model4=keras.applications.vgg16.VGG16(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape=None, pooling=None, classes=1000,\n",
    "    classifier_activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f153bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1.summary()\n",
    "base_model2.summary()\n",
    "base_model3.summary()\n",
    "base_model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27776ee",
   "metadata": {},
   "source": [
    "## setting all layers as non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model1.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False \n",
    "    \n",
    "for layer in base_model3.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in base_model4.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0599e09b",
   "metadata": {},
   "source": [
    "## Defining custom activation function\n",
    "As per the paper, custom activation function Swish is used in place of Relu in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de615148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ed143",
   "metadata": {},
   "source": [
    "## Defining convolution batch normalization function with Swish activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d85b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1)):   \n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides)(x)\n",
    "    x = Lambda(swish)(x)\n",
    "    x = BatchNormalization(axis=3)(x)  \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa11b5",
   "metadata": {},
   "source": [
    "## Defining Inception Block:\n",
    "Inception Modules are used in Convolutional Neural Networks to allow for more efficient computation and deeper Networks through a dimensionality reduction with stacked 1Ã—1 convolutions. The modules were designed to solve the problem of computational expense, as well as overfitting, among other issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception(x,nb_filter):  \n",
    "    branch1x1 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1))  \n",
    "  \n",
    "    branch3x3 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1))  \n",
    "    branch3x3 = Conv2d_BN(branch3x3,nb_filter,(3,3), padding='same',strides=(1,1))  \n",
    "  \n",
    "    branch5x5 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1))  \n",
    "    branch5x5 = Conv2d_BN(branch5x5,nb_filter,(3,3), padding='same',strides=(1,1))\n",
    "    branch5x5 = Conv2d_BN(branch5x5,nb_filter,(3,3), padding='same',strides=(1,1))\n",
    "  \n",
    "    branchpool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)  \n",
    "    branchpool = Conv2d_BN(branchpool,nb_filter,(1,1),padding='same',strides=(1,1))  \n",
    "  \n",
    "    x = concatenate([branch1x1,branch3x3,branch5x5,branchpool],axis=3)    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc661a",
   "metadata": {},
   "source": [
    "## Adding new layers in model architechture\n",
    "Global Average Pooling\n",
    "Fully connected layers are replaced by a global pooling layer to conduct the dimension reduction of feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1- VGG19\n",
    "\n",
    "x = base_model1.layers[-6].output\n",
    "\n",
    "\n",
    "x = Conv2d_BN(x,512,(3,3),strides=(1,1),padding='same')  \n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')(x) \n",
    "\n",
    "x = Inception(x,512)  \n",
    "x = Inception(x,512)  \n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions_1 = Dense(2, activation='softmax')(x)\n",
    "model1 = Model(inputs=base_model1.input, outputs=predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2 MobileNet\n",
    "\n",
    "x = base_model2.layers[-6].output\n",
    "\n",
    "\n",
    "x = Conv2d_BN(x,512,(3,3),strides=(1,1),padding='same')  \n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')(x) \n",
    "\n",
    "x = Inception(x,512)  \n",
    "x = Inception(x,512)  \n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions_2 = Dense(2, activation='softmax')(x)\n",
    "model2 = Model(inputs=base_model2.input, outputs=predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #ResNet50\n",
    "x = base_model3.layers[-6].output\n",
    "\n",
    "\n",
    "x = Conv2d_BN(x,512,(3,3),strides=(1,1),padding='same')  \n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')(x) \n",
    "\n",
    "x = Inception(x,512)  \n",
    "x = Inception(x,512)  \n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions_3 = Dense(2, activation='softmax')(x)\n",
    "model3 = Model(inputs=base_model3.input, outputs=predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b75260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-16\n",
    "x = base_model4.layers[-6].output\n",
    "\n",
    "\n",
    "x = Conv2d_BN(x,512,(3,3),strides=(1,1),padding='same')  \n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(1,1),padding='same')(x) \n",
    "\n",
    "x = Inception(x,512)  \n",
    "x = Inception(x,512)  \n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions_4 = Dense(2, activation='softmax')(x)\n",
    "model4 = Model(inputs=base_model4.input, outputs=predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()\n",
    "model2.summary()\n",
    "model3.summary()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb3bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727a6f8b",
   "metadata": {},
   "source": [
    "## Compiling the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eac15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp():\n",
    "    learning_rate=0.0001\n",
    "    decay=1e-6\n",
    "    momentum=0.8\n",
    "    nesterov=True\n",
    "    sgd_optimizer= SGD(lr = learning_rate, decay = decay, momentum = momentum, nesterov = nesterov)\n",
    "    models=['VGG-19','MobileNet','ResNet','VGG-16']\n",
    "    \n",
    "    for i in models:\n",
    "        if i=='VGG-19':\n",
    "            model1.compile(loss='categorical_crossentropy',optimizer=sgd_optimizer,metrics=['accuracy','mse'])\n",
    "        elif i=='MobileNet':\n",
    "            model2.compile(loss='categorical_crossentropy',optimizer=sgd_optimizer,metrics=['accuracy','mse'])\n",
    "        elif i=='ResNet':\n",
    "            model3.compile(loss='categorical_crossentropy',optimizer=sgd_optimizer,metrics=['accuracy','mse'])\n",
    "        else:\n",
    "            model4.compile(loss='categorical_crossentropy',optimizer=sgd_optimizer,metrics=['accuracy','mse'])\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    comp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bac8e3",
   "metadata": {},
   "source": [
    "## Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model1 VGG-19\n",
    "import time\n",
    "epochs =25\n",
    "batch_size = 10\n",
    "\n",
    "start = time.time()\n",
    "history_1 = model1.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=epochs, batch_size =batch_size,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)\n",
    "end = time.time()\n",
    "print(\"Execution Time : \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MobileNet\n",
    "epochs =25\n",
    "batch_size = 10\n",
    "import time\n",
    "start = time.time()\n",
    "history_2 = model2.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=epochs, batch_size =batch_size,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)\n",
    "end = time.time()\n",
    "print(\"Execution Time : \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50\n",
    "epochs =25\n",
    "batch_size = 10\n",
    "import time\n",
    "start = time.time()\n",
    "history_3 = model3.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=epochs, batch_size =batch_size,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)\n",
    "end = time.time()\n",
    "print(\"Execution Time : \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-16\n",
    "epochs =25\n",
    "batch_size = 10\n",
    "import time\n",
    "start = time.time()\n",
    "history_4 = model4.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=epochs, batch_size =batch_size,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)\n",
    "end = time.time()\n",
    "print(\"Execution Time : \", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_weights('mix_1epochs.h5')\n",
    "model2.save_weights('mix1_1epochs.h5')\n",
    "model3.save_weights('mix1_1epochs.h5')\n",
    "model4.save_weights('mix1_1epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98845b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d10729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf380119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d188a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "test_output_1= model1.evaluate(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "end=time.time()\n",
    "print(model2.metrics_names)\n",
    "print(test_output_1)\n",
    "print(\"testing time : \"+ str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "test_output_2= model2.evaluate(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "end=time.time()\n",
    "print(model1.metrics_names)\n",
    "print(test_output_2)\n",
    "print(\"testing time : \"+ str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92837a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "test_output_3= model3.evaluate(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "end=time.time()\n",
    "print(model1.metrics_names)\n",
    "print(test_output_3)\n",
    "print(\"testing time : \"+ str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "test_output_4= model4.evaluate(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "end=time.time()\n",
    "print(model1.metrics_names)\n",
    "print(test_output_4)\n",
    "print(\"testing time : \"+ str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65e904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={'Accuracy':[test_output_1[1],test_output_2[1],test_output_3[1],test_output_4[1]],\n",
    "     'Loss':[test_output_1[0],test_output_2[0],test_output_3[0],test_output_4[0]],\n",
    "     'MSE':[test_output_1[2],test_output_2[2],test_output_3[2],test_output_4[2]]}\n",
    "models=['VGG-19','MobileNet v2','ResNet50','VGG-16']\n",
    "df=pd.DataFrame(data,index=models)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017a316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
